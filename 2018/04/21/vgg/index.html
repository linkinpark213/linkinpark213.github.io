<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8" />

    

    

    <title>A review of VGG net - Very Deep Convolutional Neural Networks | Linkin213&#39;s Park</title>
    <meta name="author" content="Harper Long" />
    <meta name="version" content="1.0.0" />
    <meta name="keywords" content="" />
    <meta name="description" content="IntroductionConvolutional neural networks(CNN) have enjoyed great success in conputer vision research fields in the past few years. A number of attempts are made based on the original CNN architecture to improve its accuracy and performance. In 2014," />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no" />
    <meta name="baidu-site-verification" content="F0CXvmUgA9" />

    
    
    <link rel="icon" href="/images/favicon.png">
    

    <link rel="stylesheet" href="/css/style.css">
</head>
<body>

    <div class="app">
        <header class="header clearfix">
    <div id="nav" class="nav">
    <button id="open-panel" class="open-panel"><i class="icon-library"></i></button>

    <nav class="nav-inner">

        
        
        <li class="nav-item">
            <a class="nav-link" href="/">Home</a>
        </li>
        
        
        
        <li class="nav-item nav-item-tag">
            <a id="nav-tag" class="nav-link" href="#">Tags</a>
            <div id="nav-tags" class="nav-tag-wrap">
                <i class="nav-tag-arrow"></i>
                
  <div class="widget-wrap">
    <h3 class="widget-title">
        <i class="icon-tag vm"></i>
        <span class="vm">标签</span>
    </h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Blogging/">Blogging</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Computer-Vision/">Computer Vision</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Other/">Other</a></li></ul>
    </div>
  </div>


            </div>
        </li>
        
        
        
        <li class="nav-item">
            <a class="nav-link" href="/archives">Archives</a>
        </li>
        
        
        
        <li class="nav-item">
            <a class="nav-link" href="/atom.xml">RSS</a>
        </li>
        
        
        
        <li class="nav-item">
            <a class="nav-link" href="/about">About</a>
        </li>
        
        
        

    </nav>
</div>

    <aside id="aside" class="aside">
    <div id="aside-mask" class="aside-mask"></div>
    <div id="aside-inner" class="aside-inner">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit"><i class="icon-search-stroke"></i></button><input type="hidden" name="sitesearch" value="http://linkinpark213.com"></form>

        
        
        
        

        
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#VGG-net-39-s-ancestors"><span class="toc-number">2.</span> <span class="toc-text">VGG net&#39;s ancestors</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#LeNet-The-Origin"><span class="toc-number">2.1.</span> <span class="toc-text">LeNet: The Origin</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AlexNet-The-Powerful-Convolution"><span class="toc-number">2.2.</span> <span class="toc-text">AlexNet: The Powerful Convolution</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#VGG-Nets"><span class="toc-number">3.</span> <span class="toc-text">VGG Nets</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Stacks-of-Smaller-Convolution-Filters"><span class="toc-number">3.1.</span> <span class="toc-text">Stacks of Smaller Convolution Filters</span></a></li></ol></li></ol>
        
    </div>
</aside>

</header>

        <div id="content" class="content"><article class="article" itemscope itemprop="blogPost">
    
    <header class="article-header">
        
        <h1 itemprop="name">
            A review of VGG net - Very Deep Convolutional Neural Networks
        </h1>
        
        
        <div class="article-meta clearfix">
            <a class="article-date" href="/2018/04/21/vgg/">
    
    <i class="icon-calendar"></i>
    
    <time datetime="2018-04-21T08:15:55.000Z" itemprop="datePublished">2018-04-21</time>
</a>

            
<div class="article-tag-list">
    <i class="icon-tag"></i>
    <a class="article-tag-link" href="/tags/Computer-Vision/">Computer Vision</a>, <a class="article-tag-link" href="/tags/Deep-Learning/">Deep Learning</a>
</div>


        </div>
        
    </header>
    
    <section class="article-body markdown-body">
        
        <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Convolutional neural networks(CNN) have enjoyed great success in conputer vision research fields in the past few years. A number of attempts are made based on the original CNN architecture to improve its accuracy and performance. In 2014, Karen Simonyan et al did an investigation on the effect of depth on CNNs&#39; accuracy in large-scale image recognition (thus also proposing a series of very deep CNNs which are usually called VGG nets). The result confirmed the importance of CNN depth in visual representations.</p>
<h2 id="VGG-net-39-s-ancestors"><a href="#VGG-net-39-s-ancestors" class="headerlink" title="VGG net&#39;s ancestors"></a>VGG net&#39;s ancestors</h2><p>Before introcducing VGG net, let&#39;s take a glance at prior convolutional neural networks. </p>
<h3 id="LeNet-The-Origin"><a href="#LeNet-The-Origin" class="headerlink" title="LeNet: The Origin"></a>LeNet: The Origin</h3><p>Basic neural network structures(for example, multi-layer preceptron) learn patterns on 1D vectors, which cannot cope with 2D features in images well. In 1986, Lecun et al proposed a convolution network model called LeNet-5. Its structure is fairly simple: two convolution layers, two subsampling layers and a few fully connected layers. This network was used to solve a number recognition problem. (If you need to learn more about the convolution operation, please refer to Google or <em>Digital Image Processing</em> by Rafael C. Gonzalez)</p>
<a id="more"></a>
<div align="center"><br><img src="/images/lenet.png" alt="LeNet"><br></div>

<h3 id="AlexNet-The-Powerful-Convolution"><a href="#AlexNet-The-Powerful-Convolution" class="headerlink" title="AlexNet: The Powerful Convolution"></a>AlexNet: The Powerful Convolution</h3><p>In 2012, Alex Krizhevsky et al won the first place in ILSVRC-2012(ImageNet Large-Scale Visual Recognition Challenge 2012) and achieved the highest top-5 error rate of 15.3% with a convolutional network model, while the second-best entry only achieved 26.2%. The network, namely AlexNet, was trained on two GTX580 3GB GPUs parallenized. Since a single GTX580 GPU has only 3GB memory, the maximum size of networks is limited. This model proved the effectiveness of CNNs under complicated circumstances and the power of GPUs. So what if the network can go deeper? Will the top-5 error rate get even lower?</p>
<div align="center"><br><img src="/images/alexnet.png" alt="AlexNet"><br></div>

<h2 id="VGG-Nets"><a href="#VGG-Nets" class="headerlink" title="VGG Nets"></a>VGG Nets</h2><p>Here comes our hero - VGG nets. By the way, VGG is not the name of the network, but the name of the authors&#39; group - <em>Visual Geometry Group</em>, from Department of Engineering Science, University of Oxford. The networks they proposed were therefore named after the group. The main contributions of VGG nets are: 1. more but smaller convolution filters; 2. great depth of networks.</p>
<h3 id="Stacks-of-Smaller-Convolution-Filters"><a href="#Stacks-of-Smaller-Convolution-Filters" class="headerlink" title="Stacks of Smaller Convolution Filters"></a>Stacks of Smaller Convolution Filters</h3><p>Rather than using relatively large receptive fields in the first convolution layers, Simonyan et al selected very small 3x3 receptive fields throughout the whole net, which are convolved with the input at every pixel with a stride of 1. As is shown in the figures below, a stack of two 3x3 convolution layers has an effective receptive field of 5x5. We can also conclude that a stack of three 3x3 convolution filters has an effective receptive field of 7x7.</p>
<div align="center"><br>    <img src="/images/conv1.png" width="50%" height="50%" alt="Conv5x5"><br>    <img src="/images/conv2.png" width="50%" height="50%" alt="Conv3x3x2"><br></div>
      <script>
        window.disqusProxy={
          shortname: 'linkinpark213',
          username: 'someone',
          server: '67.218.155.58',
          port: 5509,
          adminAvatar: '/avatars/admin-avatar.jpg',
          identifier: '2018/04/21/vgg/',
        };
        window.disqus_config = function () {
          this.page.url = window.location.href;
          this.page.identifier = window.disqusProxy.identifier;
        };
      </script>
        
    </section>
</article>



<div class="comments">
    
      <script src="//cdn.bootcss.com/react/16.0.0/umd/react.production.min.js"></script>
      <script src="//cdn.bootcss.com/react-dom/16.0.0/umd/react-dom.production.min.js"></script>
      <script src="//cdn.bootcss.com/fetch/2.0.3/fetch.min.js"></script>
      <script src="//cdn.jsdelivr.net/npm/blockies-identicon@0.1.0/blockies.min.js"></script>
      <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"/>
      <div id="disqus_proxy_thread"><script src="/scripts/hexo-disqus-proxy-primary.js" async></script>
        <p class="comment-tips">国内查看评论需要代理~</p>
    </div>
    <script>
    window.disqus_config = function () {
        this.language = 'zh';
        this.page.url = 'http://linkinpark213.com/2018/04/21/vgg/';
        this.page.title = 'A review of VGG net - Very Deep Convolutional Neural Networks';
        this.page.identifier = '2018/04/21/vgg/';
    };
    (function() { // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');
        
        s.setAttribute('data-timestamp', +new Date());
        
    })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

</div>
        <footer class="footer">
    Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, Theme by <a href="https://github.com/sanonz/hexo-theme-concise" target="_blank">Concise</a>
</footer>

<script type="text/javascript" src="//s13.cnzz.com/z_stat.php?id=1234567890&amp;web_id=1234567890"></script>


    </div>

    <script type="text/javascript" src="https://cdn.bootcss.com/jquery/1.9.0/jquery.min.js"></script>
    
    <script type="text/javascript" src="/js/scrollspy.min.js"></script>
    
    <script type="text/javascript">
        $(function() {
            var nodes = {
                nav: $('#nav'),
                aside: $('#aside'),
                navTags: $('#nav-tags')
            };

            $('#open-panel, #aside-mask').on('click', function() {
                nodes.aside.toggleClass('panel-show');
            });
            $('#nav-tag').on('click', function(event) {
                event.preventDefault();console.log(nodes.navTags.attr('class'))
                nodes.navTags.toggleClass('tag-show');console.log(nodes.navTags.attr('class'))
            })/*.hover(function() {
                nodes.navTags.addClass('tag-show');
            }, function() {
                nodes.navTags.removeClass('tag-show');
            });*/

            
            $(document.body).scrollspy({target: '#aside-inner'});
            
        });
    </script>

</body>
</html>
